{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "from numba import njit\n",
    "from collections import defaultdict, Counter\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load tokens from extracted wiki articles\n",
    "# Run cell in text_normalization.ipynb first!!!\n",
    "with open(\"data/wiki_tokens.txt\", \"rb\") as f:\n",
    "    tokens = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save(\"data/model.txt\") # Save model to txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectors = model[model.wv.vocab] # Get array of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_tsv(m):\n",
    "    words = m.wv.vocab.keys()\n",
    "    metadata = \"\\n\".join(words)\n",
    "    vectors = \"\\n\".join([\"\\t\".join(row) for row in m[words].astype('str').tolist()])\n",
    "    return metadata, vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "md, v = convert_tsv(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = model.wv.vocab.keys()\n",
    "\n",
    "with open(\"data/gensim_vectors.tsv\", \"w\") as f:\n",
    "    writer = csv.writer(f, delimiter=\"\\t\", lineterminator=\"\\n\")\n",
    "    for row in model[words]:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"data/gensim_metadata.tsv\", \"w\", encoding=\"UTF8\") as f:\n",
    "    writer = csv.writer(f, delimiter=\"\\n\")\n",
    "    writer.writerow(words)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
